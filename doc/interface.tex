\documentclass[a4paper]{article}
\usepackage[a4paper, left=25mm, right=25mm, top=25mm, bottom=25mm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{indentfirst}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{pdflscape}

\DeclareMathOperator*{\argmin}{arg\,min}

\newcommand{\F}{\mathcal{F}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\conv}{\mbox{conv}\,}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\title{On the feasibility for the system of quadratic equations\\MATLAB Library}
\date{}
\author{Anatoly Dymarsky, Elena Gryazina, Boris Polyak, Sergei Volodin}

\begin{document}
\maketitle
\section{Notations}
The goal of the project is to solve a number of tasks for quadratic maps, which are
\begin{enumerate}
\item (Real case) The map $f\colon \mathbb{R}^n\to\mathbb{R}^m$ s.t. $$f_i(x)=x^TA_ix+2b_i^Tx,\, A_i=A_i^T$$
\item (Complex case) The map $f\colon \mathbb{C}^n\to\mathbb{R}^m$ s.t. $$f_i(x)=x^*A_ix+b_i^*x+x^*b_i,\, A_i=A_i^*$$
Where $\cdot^*$ is Hermitian conjugate.
\end{enumerate}

From this point on, $X$ denotes $\mathbb{R}^n$ for real case or $\mathbb{C}^n$ for complex case.

We use the following notations:
\theoremstyle{definition}
\begin{definition} For a vector $c\in\mathbb{R}^n$ and tuple of matrices $(A_1,...,A_n)$ (or vectors) the dot product is defined as following: $$c\cdot A=\sum\limits_{i=1}^nc_iA_i$$
\end{definition}
\begin{definition} The image of $f$ is denoted as $F$:
	$$F=f(X)$$
\end{definition}
\begin{definition} The convex hull of $F$ is denoted as $G$:
	$$G=\conv F$$
\end{definition}
\begin{definition} The boundary points of $F$ touched by a tangent hyperplane with normal vector $c\in\mathbb{R}^m$:
	$$\partial F_c=\argmin\limits_{y\in F}(c,y)$$
\end{definition}
\begin{definition} The boundary points of $G$ touched by a tangent hyperplane with normal vector $c\in\mathbb{R}^m$:
	$$\partial G_c=\argmin\limits_{y\in G}(c,y)$$
\end{definition}
\section{Functions}
The library consists of a number of functions defined in separate .m files. Input format for the map is the following: 

\begin{itemize}
\item The number $A(i, j, k)$ denotes $i$'th row and $j$'th column of the matrix $A_k$
\item The number $b(i, j)$ denotes $i$'th element of the vector $b_j\in\mathbb{R}^m$
\end{itemize}

\begin{enumerate}
\item {\bf Feasibility membership oracle}\\
{\bf Given:}
\begin{itemize}
\item The map $f$ as matrices $A$ and vectors $b$
\item A point $y\in\mathbb{R}^m$.
\end{itemize}
{\bf Determine:} if $y\in F$
\begin{verbatim}
is_infeasible = infeasibility_oracle(A, b, y)
\end{verbatim}
This function tries to separate the point $y$ from the convex hull $G$ with a hyperplane. See Theorem 3.2 from the article.

{\bf Return value:}
\begin{itemize}
\item $1$ means that the separation was successful and the point $y\notin G$. This implies $y\notin F$.
\item $0$ means that the feasibility is uncertain.
\end{itemize}

\item {\bf Boundary oracle}\\
{\bf Given:}
\begin{itemize}
	\item The map $f$ as matrices $A$ and vectors $b$
	\item A point $y\in F$
	\item A direction $d\in\R^m$
\end{itemize}
The following two tasks are considered:
\begin{enumerate}
\item \begin{verbatim}
[t, is_in_F] = boundary_oracle(A, b, y, d)
\end{verbatim}
This function finds the point $y+td$ on the boundary $\partial G$ with the largest $t$:
$$t = \sup\{\tau\big| y+\tau d\in G\}$$
{\bf Return value:}
\begin{itemize}
	\item $t$ is the largest step in direction $d$
	\item is\_in\_F is a binary variable indicating if the resulting point $y+td$ belongs to $F$
\end{itemize}

{\bf Exception:} if optimization task failed

\item \begin{verbatim}
c = get_c_from_d(A, b, y, d)
\end{verbatim}

This function obtains the normal vector $c$ at the boundary point $y+td$ using dual problem (5) from the article.

{\bf Return value:} the normal vector $c$ s.t. $y+td\in\partial G_c$

{\bf Exception:} if optimization task failed
\end{enumerate}

\item {\bf Nonconvexity certificate}\\
{\bf Given:}
\begin{itemize}
	\item The map $f$ as matrices $A$ and vectors $b$
	\item A point $y\in F$
	\item Number of iterations $k$
\end{itemize}
The following two tasks are considered:
\begin{enumerate}
	\item \begin{verbatim}
	c = get_c_minus(A, b, y, k)
	\end{verbatim}
	This function runs $k$ iterations of the following procedure:
	\begin{enumerate}
		\item Generate random direction $d$
		\item Obtain a normal vector $c$ using get\_c\_from\_d()
		\item Check if $\partial F_c$ is nonconvex using Theorem 3.4 from the article
		\item Return $c$ if so, continue otherwise
	\end{enumerate}

	{\bf Return value:}  $c$ s.t. $\partial F_c$ is nonconvex
	
	{\bf Exception:} if $c$ was not found in $k$ iterations
	
	\item \begin{verbatim}
	is_nonconvex = nonconvexity_certificate(A, b, y, k)
	\end{verbatim}
	
	This function runs get\_c\_minus() and outputs $1$ if the normal vector $c$ was found. In this case the image $F$ is guaranteed to be nonconvex.
	
	{\bf Return value:} $1$ if $F$ is nonconvex, $0$ if result is uncertain
\end{enumerate}

\item {\bf Positive-definite $c\cdot A$}\\
{\bf Given:}
\begin{itemize}
	\item The map $f$ as matrices $A$ and vectors $b$
	\item The initial normal vector $p$
\end{itemize}
The following three tasks are considered:
\begin{enumerate}
	\item \begin{verbatim}
	c_plus = get_near_c_plus(A, p, gamma);
	\end{verbatim}

	This function finds the nearest to $p$ vector $c_+$ such that
	$$c_+\cdot A\succeq 0$$
	
	via solving the following optimization task ($c_{+\bot}$ is the part of $c_+$ orthogonal to $p$):

\begin{align}
\min & ~\gamma \|c_+\|^2+c^2_{+\bot} \nonumber\\
c_+\cdot A-I&  \succeq 0 \nonumber\\
(c_+, p) & \geqslant 0 \nonumber
\end{align}

	{\bf Return value:}  $c_+$ s.t. $c_+\cdot A\succeq 0$
	
	{\bf Exception:} if $c_+$ was not found
	
	\item \begin{verbatim}
	c_plus = get_c_plus(A, k)
	\end{verbatim}
	
	This function generates a random vector $p$ and then finds $c_+$ nearest to it. Function generates at most $k$ vectors $p$.
	
	{\bf Return value:} $c_+$ s.t. $c_+\cdot A\succeq 0$
	
	{\bf Exception:} if $c_+$ was not found
	
	\item \begin{verbatim}
	c_plus = get_best_plus(A)
	\end{verbatim}
	
	This function returns the ''best'' vector $c_+$ s.t. $c_+\cdot A\succeq 0$ via the following problem:
\begin{align}
\max & ~\lambda_{\min}(c_+\cdot A) \nonumber\\
\|c\|^2&  \leqslant 1 \nonumber
\end{align}
	
The spectrum of the resulting matrix $c_+\cdot A$ is separated from $0$ the most.
	
	{\bf Return value:} $c_+$ s.t. $c_+\cdot A\succeq 0$
	
	{\bf Exception:} if $c_+$ was not found
\end{enumerate}

\item {\bf Convex subpart}

{\bf Given:}
\begin{itemize}
	\item The map $f$ as matrices $A$ and vectors $b$
	\item The point $y\in F$
	\item Number of iterations $k$
	\item Vector $c_+$ s.t. $c_+\cdot A\succeq 0$
	\item Number of iterations k\_c\_minus for the nonconvexity certificate
\end{itemize}
\begin{verbatim}
z_max = get_z_max(A, b, y, k, c_plus, k_c_minus)
\end{verbatim}
This function performs the following procedure $k$ times:
\begin{enumerate}
\item Changing basis with change\_basis
\item Obtaining $c\in C_-$ using get\_c\_minus
\item Minimizing $z(c)$ using $c$ as a starting point
\end{enumerate}

The resulting $z_{\max}$ is a minimum over all obtained $z$'s

{\bf Return value:} Minimal value $z_{\max}$ or Inf if no nonconvexities were found

{\bf Exception:} None
\end{enumerate}
\begin{landscape}
{\bf Other functions}\\\\
\begin{tabular}{|p{28mm}|c|p{50mm}|c|p{30mm}|c|}
	\hline
	\bf Name & \bf Input & \bf Call & \bf Description & \bf Return value & \bf Exception\\\hline
	\bf Random map & {Dimensions n, m} & get\_random\_f(n, m, is\_complex) & Generates random map $f$ & [A, b] & None\\\hline
	\bf Value at x & The point $x\in X$ & quadratic\_map(A, b, x) & Calculates $f(x)$ & $y=f(x)$ & None\\\hline
	\bf Product $c\cdot A$ & Normal vector $c$ & get\_Ac(A, c) & Calculates $c\cdot A$ & $A_c=c\cdot A$ & None\\\hline
	\bf Get $H_c$ & $c,y\in\R^m$ & get\_H\_c(A, b, c, y) & $H_c=\left(\begin{array}{cc}A_c & b_c\\b_c' &-(c,y) \end{array}\right)$ & $H_c$ & None\\\hline
	\bf Minimize $z(c)$ & $c,c_+$, step $\beta$ & minimize\_z\_c(A, b, c, c\_plus, beta\_initial, max\_step) & Calculates $\inf\limits_{c\in C_-}z(c)$ & [z, c\_array, z\_array] & If failed\\\hline
	\bf  $\R^n$ projection & & project(A, b, c, x\_0, delta\_c, normal, search\_area\_size) & Projects $c+\Delta c$ to $C_-$ & [c\_new, lambda] & If failed\\\hline
	\bf $\mathbb{C}^n$ projection & & project\_descent(A, b, c, normal\_1, normal\_2) & Projects $c$ to $C_-$ & [c\_new, distance] & If failed\\\hline
	\bf Gradient $\frac{\partial z}{\partial c}$ & Normal $c$ & get\_dz\_dc(A, b, c) & Calculates $Q$, $\nabla z(c)$, normal vectors $n_1$, $n_2$ & [Q, Q\_inv, k, v, lambda\_min, z, dz\_dc, normal\_re, normal\_im, drho\_dc] & None\\\hline
	\bf Change of basis & $c_+$ & change\_basis(A, b, c\_plus) & $\begin{cases}
	x = S(x'+x_0)\\
	y = y' + y_0
	\end{cases}
	$ s.t.
	$\begin{cases}
	c_+\cdot A_0=I\\
	c_+\cdot b_0=0
	\end{cases}$ & [A\_new, b\_new, x0, y0] & None\\\hline
\end{tabular}
\end{landscape}
\end{document}
