\documentclass[a4paper]{article}
\usepackage[a4paper, left=25mm, right=25mm, top=25mm, bottom=25mm]{geometry}
%\geometry{paperwidth=210mm, paperheight=2000pt, left=5pt, top=5pt}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{indentfirst}
\usepackage{tikz} %Рисование автоматов
\usetikzlibrary{automata,positioning,arrows,trees}
\usepackage{amsmath}
\usepackage{enumerate}
\usepackage[makeroom]{cancel} % зачеркивание
\usepackage{multicol,multirow} %Несколько колонок
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\conv}{conv}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator*{\argmin}{arg\,min}
\usepackage{wasysym}
\date{}
\title{On the feasibility for the system of quadratic equations, explanations}

\begin{document}
\maketitle
\subsection*{1. Theorem 3.2 (Sufficient condition)}
Consider $f\colon \mathbb{R}^n\to\mathbb{R}^m$, s.t. $f_i(x)=x^TA_ix+2b_i^Tx$, $A_i=A_i^T$. Define $F=f(\mathbb{R}^n)$.

Then why $A=\inf \limits_{y\in F} (c,y)=\inf\limits_{y\in\conv F} (c,y)=B$?

\begin{enumerate}
\item First, $F\subseteq \conv F$, therefore, $B\leqslant A$.
\item Secondly, let $y_k\in \conv F$ be a sequence s.t. $g_k=(c,y_k)\underset{k\to\infty}{\longrightarrow} B$. $y_k=\sum\limits_{i=1}^{n_k}\alpha^k_iy^k_i$.

$g_k(c,y_k)=\sum\limits_{i=1}^{n_k}\alpha^k_i(c,y^k_i)=\sum\limits_{i=1}^{n_k}\alpha^k_i g^k_i$. Define $g^k_0=\min\limits_{i\in \overline{1,n_k}}g^k_i$. Then $B\leqslant g^k_0\leqslant g^k$. Therefore, $g^k_0\to B$ also. This way, we have constructed a sequence $y^k_0\in F$ s.t. $(c,y^k_0)\to B$, therefore, $A\leqslant B$.
\end{enumerate}

\subsection*{2. Minimum of $f(x)$}
Consider $f\colon \mathbb{R}^n\to\mathbb{R}^m$. $f_i(x)=x^TA_ix+2b_i^Tx$. $A_i^T=A_i$. Let $c\in\mathbb{R}^m$

We want to find
$g(c)=\inf\limits_{x\in\mathbb{R}^n} (c,f(x))$.

Define $A_c\equiv c\cdot A=\sum\limits_{i=1}^m c_iA_i$, $b_c=c\cdot b=\sum\limits_{i=1}^m c_ib_i$.

$(c,f(x))=\sum\limits_{i=1}^m c_i f_i(x)=\sum c_i (x^TA_ix+2b_i^Tx)=x^TA_cx+2b_c^Tx$.

If $\exists v\colon -\alpha=v^TA_cv<0$ then $g(c)=-\infty$:
$g(\beta v)=-\beta^2\alpha+\beta 2b_c^Tv\to-\infty,\,\beta\to+\infty$.

From this point on, we assume $A_c\geqslant 0$. Let $R_0$ be a zero eigenspace (=kernel) of $A_c$: $R_0=\{v\colon A_cv=0\}=\ker A_c$

If $\exists v\in R_0\colon v^Tb_c\neq 0$ then $g(c)=-\infty$: Consider $f(\beta v)=\beta^2 v^T\cancelto{0}{(A_cv)}+2\beta \underbrace{b_c^Tv}_{\neq 0}\to-\infty,\, \beta\to\infty$

Then $R_0\subseteq \{b_c\}^\bot$

Consider $A=\sum\limits_{i=1}^n \lambda_i s_is_i^T=S\Lambda S^T$, $S=||s_1 ... s_n ||$, $S^TS=E$, $s_i^Ts_j=\delta_{ij}$.

$f$ is differentiable, then for finding $g(c)$ the gradiend $\nabla (c,f(x))=2A_cx+2b_c=0$.

$$S\Lambda S^Tx=-b_c\Leftrightarrow \Lambda S^Tx=-S^Tb_c\, (*)$$.

Let $x$ be $x=x^{\parallel}+x^\bot$, $x^{\parallel}\in R_0$, $x^\bot \bot R_0$.

Then neither $f(x)$ nor $\Lambda S^T x$ depend on $x^{\parallel}$. This means that the $x$ minimizing $g(c)$ is defined in terms of $x^{\bot}$ and $x^{\parallel}$ is arbitrary.

Define $\lambda^g_i=\begin{cases}
0,&\lambda_i=0\\
1/\lambda_i,&\lambda_i\neq 0
\end{cases}$. Define $\Lambda^g=\diag(\lambda^g_1,...,\lambda^g_n)$. Then $\Lambda \Lambda^g=\delta_{ij}[\lambda_i\neq 0]$. Then $S\Lambda^g\Lambda S^T$ is a projector on $R_0^\bot$.

Consider $(*) \Leftrightarrow \Lambda^g\Lambda S^T(x^\parallel+x^\bot)=-\Lambda^gS^Tb_c$. But $\Lambda S^Tx^\parallel=0$, therefore, $\underbrace{S\Lambda^g\Lambda S^T}_{\mbox{\tiny projector}}x^\bot=-S\Lambda^gS^Tb_c$. But $x^\bot$ is already in $R_0^\bot$, therefore, $x^\bot=-\underbrace{S\Lambda^gS^T}_{A^g_c}b_c$. Here $A_c^g$ is a pseudoinverse of $A_c$.

Therefore, $\boxed{x=-A_c^gb_c+x^\parallel}$, where $x^\parallel\in R_0$.

%Let us notice that since $A_c^{gT}=A_c^g$

Consider $(c,f(x))=(c,f(x^\bot))=b_c^TA_c^gA_cA_c^gb_c-2b_c^TA_c^gb_c$. Consider $A_cA_c^gb_c=S\Lambda \cancelto{E}{S^TS}\Lambda^gS^Tb_c$. Because $R_0\subseteq\{b_c\}^\bot$, $\Lambda\Lambda^gS^Tb_c=S^Tb_c$. Therefore, $A_cA_c^gb_c=b_c$. Then $(c,f(x))=b_c^TA_c^gb_c-2b_c^TA_c^gb_c=\boxed{-b_c^TA_c^gb_c}$

\subsection*{3. Finding $c$ provided $d$}
Let $H\colon \mathbb{R}^{n+1, n+1}\to \mathbb{R}^n$ be a map s.t. $H_i(X)=\Tr(H_iX)$, $$H_i=\left|\left|
\begin{array}{cc}
A_i & b_i\\
b_i^T & 0
\end{array}
\right|\right|^{\Box}$$.

Consider a boundary point $X$, which is a solution of (main article, (4)):
$$\boxed{\sup\limits_{\begin{cases}
H(X)=y^0+td\\
X\geqslant 0\\
X_{n+1,n+1}=1
	\end{cases}} t}$$

Define $f(t,X)=t$, $D_0=\{(t,X)\big| X\geqslant 0,\, X_{n+1,n+1}=1 \}$, $D_1=\{(t,X)\big| H(X)=y^0+td\}$.

Then supremum is equivalent to

$$\sup\limits_{(t,X)\in D_0\cap D_1}f(t,X)$$

Define a Lagrange function $L(c,t,X)=\underbrace{t}_{f(t,X)}+\sum\limits_{i=1}^m c_i(y^0_i+td_i-H_i(X))$.

Here we divided the constraints into two parts: $D_1$ goes to the Lagrange function, $D_0$ goes to the inner supremum. {\em Stephen Boyd, Lieven Vandenberghe. Convex Optimization. Page ???. Cambridge University Press}

Then the dual function is $g(c)=\sup\limits_{(t,X)\in D_0} L(c,t,X)$.

Because $L=t(1+\sum\limits_{i=1}^m c_id_i)+\sum\limits_{i=1}^n c_i(y^0_i-H_i(X))$, $g=+\infty$ when $(c,d)\neq -1$. From this point we assume that $\boxed{(c,d)=-1}$.

Now, $g(c)=\sup\limits_{X_{n+1,n+1}=1,X\geqslant 0} (c,y^0-H(X))=(c,y^0)+\sup\limits_{y\in\conv F} -(c,y)=(c,y^0)-\inf\limits_{y\in\conv F} (c,y)$.

Then the dual problem is
$$g(c)\to\inf\limits_{(c,d)=-1}$$

Let us prove that $\inf\limits_{y\in\conv F} (c,y)=\inf\limits_{H=\left|\left|
\begin{array}{cc}
A_c & b_c\\
b_c^T&\gamma
\end{array}
\right|\right|\geqslant 0}(-\gamma)$

Via Schur complement $H\geqslant 0\Leftrightarrow \begin{cases}
A_c\geqslant 0\\
\gamma-b_c^TA_c^gb_c\geqslant 0\\
(E-A_cA_c^g)b_c=0
\end{cases}$.

$A_c\geqslant 0$ is a necessary condition for $\exists g(c) \in\mathbb{R}$ (see part 2).

$(E-A_cA_c^g)b_c=0$ is another necessary condition for $\exists g(c)\in\mathbb{R}$.

Statement $\gamma\geqslant b_c^TA_cb_c$ means $-\gamma\leqslant -b_c^TA_cb_c=\inf\limits_{y\in\conv F}(c,y)$, which means that $-\gamma$ is a lower bound for $\inf\limits_{y\in\conv F}(c,y)$.

Then $H\geqslant 0\Leftrightarrow -\gamma\leqslant \inf\limits_{y\in\conv F}(c,y)$.

Then $g(c)=(c,y^0)-\inf\limits_{H\geqslant 0}{-\gamma}$.

Then the dual problem is:

$\inf\limits_{(c,d)=-1}g(c)\Leftrightarrow \inf\limits_{(c,d)=-1}\left[(c,y^0)-\inf\limits_{H\geqslant 0}(-\gamma)\right]\Leftrightarrow \inf\limits_{(c,d)=-1}\inf\limits_{H\geqslant 0}(c,y^0)+\gamma=\boxed{\inf\limits_{\begin{cases}
H\geqslant 0\\
(c,d)=-1
\end{cases}}\gamma+(c,y^0)}$.

This problem is exactly (5) from main article $\blacksquare$.

\subsection*{4. What is $z_{\max}$?}
Consider $f\colon\mathbb{R}^n\to\mathbb{R}^m$, $f_i(x)=x^TA_ix+2b_i^Tx$, $A_i=A_i^T$.

Let $c_+\in\mathbb{R}^m$ s.t. $A_+=\sum c_iA_i > 0$. Then the minimum $\inf\limits_x (c,f(x))$ is obtained at a single point $x_0=-A_+^{-1}b_+$, $b_+=\sum c_ib_i$.

Consider $S_\varepsilon^+=\{x\in\mathbb{R}^n\big| (x-x_0)^TA_+(x-x_0)= \varepsilon^2\}$. Then $f(S_\varepsilon^+)=\{y\in\mathbb{R}^m\big| (c_+,y)=(c_+,f(x_0))+\varepsilon^2 \}$.

Indeed, if $\begin{cases}
P=(c_+,f(x)-f(x_0))\\
Q=(x-x_0)^TA_+(x-x_0)
\end{cases}$
then $P-Q=\underline{x^TA_+x}-x_0^TA_+x_0+2b_+^Tx-2b_+^Tx_0-\underline{x^TA_+x}-x_0^TA_+x_0+2x^TA_+x_0=\left/x_0=-A_+^{-1}b_+\right/=2x_0^Tb_++2b_+^Tx-2b_+^Tx_0-2x^Tb_+=0$.

$\boxed{\mbox{{\bf Therefore, the image of $B_\varepsilon^+$ is a {\em convex cut}} $\{y\big| (c_+,y)\in (c_+,f(x_0))+[0,z_{\max}]\}$}}$

\subsection*{5. Variables s.t. $c\cdot A=I,\,c\cdot b=0$}
Given: the map $f\colon\mathbb{R}^n\to\mathbb{R}^m$, $f_i(x)=x^TA_ix+2b_i^Tx$, $A_i=A_i^T$, vector $c\in\mathbb{R}^m$

We need to find a new pair of bases s.t. $\begin{cases}
\tilde{c}\cdot \tilde{A}=I & (1)\\
\tilde{c}\cdot \tilde{b}=0 & (2)
\end{cases}$
\begin{enumerate}
\item Condition (1). Changing variables in the $x$ space: $x=S\tilde{x}\Leftrightarrow \tilde{x}=S^Tx$, $S^TS=E$. Then $f_i(x)=x^TA_ix+2b_i^Tx=\tilde{x}^T\tilde{A_i}x+2\tilde{b_i}^T\tilde{x}$. $\tilde{A_i}=S^TA_iS$. $c\tilde{A}=\sum c_i\tilde{A_i}=\sum\limits c_iS^TA_iS=S^TA_cS$. Therefore, condition $(1)$ is equal to diagonalising $A_c$. Consider $||c\cdot \tilde{b}||=||\sum c_iS^Tb_i||=||S^T\sum c_ib_i||=||\sum c_ib_i||$. Therefore, a change of variables in the $x$ space does not affect on the value of $c\cdot b$
\item Condition (2) depends on $\mbox{Rg}\,b$.
\end{enumerate}
\subsection*{6. $z(c)=?$}
Given: the map $f\colon\mathbb{R}^n\to\mathbb{R}^m$, $f_i(x)=x^TA_ix+2b_i^Tx$, $A_i=A_i^T$, two vectors $c,c_+\in\mathbb{R}^m$. $c_+A=I$, $c_+b=0$.
Find: $z(c)=\inf\limits_{y\in Y} (c_+, y)$ where $Y$ is an intersection of $f(\mathbb{R}^n)$ with a tangent hyperplane defined by its normal vector $c$.

\begin{enumerate}
\item In part 2 $Y$ was found explicitly: $Y=\{f(x)\big|x=x^\parallel-A_c^gb_c, x^\parallel \in\Ker A_c\}$. Then for $y\in Y$ $(c_+,y)=x^T(\cancelto{I}{c_+\cdot A})x+2(\cancelto{0}{c_+\cdot b})^Tx=\boxed{x^Tx}$
\item $x^Tx=||x||^2=||x^\parallel||^2+||A_c^gb_c||^2$. We want to minimize $(c_+,y)$, therefore, we choose $x^\parallel=0$. Then $z(c)=||A_c^gb_c||^2=\boxed{\big|(c \cdot A)^{-1}c\cdot b \big|^2}$
\end{enumerate}
\end{document}